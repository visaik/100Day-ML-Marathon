{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "#LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = [0.95, 0.75, 0.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 2.0409 - acc: 0.2771 - val_loss: 1.8726 - val_acc: 0.3366\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.8119 - acc: 0.3638 - val_loss: 1.7648 - val_acc: 0.3794\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7317 - acc: 0.3913 - val_loss: 1.6971 - val_acc: 0.4041\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6735 - acc: 0.4123 - val_loss: 1.6615 - val_acc: 0.4125\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6249 - acc: 0.4301 - val_loss: 1.6128 - val_acc: 0.4330\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5854 - acc: 0.4445 - val_loss: 1.5768 - val_acc: 0.4463\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5513 - acc: 0.4562 - val_loss: 1.5540 - val_acc: 0.4528\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5235 - acc: 0.4656 - val_loss: 1.5401 - val_acc: 0.4507\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4959 - acc: 0.4743 - val_loss: 1.5189 - val_acc: 0.4601\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4706 - acc: 0.4831 - val_loss: 1.4997 - val_acc: 0.4654\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4460 - acc: 0.4922 - val_loss: 1.4909 - val_acc: 0.4665\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4232 - acc: 0.4995 - val_loss: 1.4646 - val_acc: 0.4767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.4012 - acc: 0.5068 - val_loss: 1.4759 - val_acc: 0.4747\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3821 - acc: 0.5128 - val_loss: 1.4346 - val_acc: 0.4932\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3643 - acc: 0.5206 - val_loss: 1.4372 - val_acc: 0.4896\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3451 - acc: 0.5269 - val_loss: 1.4188 - val_acc: 0.4977\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3273 - acc: 0.5327 - val_loss: 1.4100 - val_acc: 0.4988\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3105 - acc: 0.5399 - val_loss: 1.4007 - val_acc: 0.5071\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2928 - acc: 0.5436 - val_loss: 1.4174 - val_acc: 0.4986\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2791 - acc: 0.5485 - val_loss: 1.3897 - val_acc: 0.5069\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2629 - acc: 0.5558 - val_loss: 1.3842 - val_acc: 0.5124\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2467 - acc: 0.5594 - val_loss: 1.3685 - val_acc: 0.5135\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2305 - acc: 0.5674 - val_loss: 1.3897 - val_acc: 0.5080\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.2180 - acc: 0.5693 - val_loss: 1.3907 - val_acc: 0.5121\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2004 - acc: 0.5759 - val_loss: 1.3637 - val_acc: 0.5213\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1913 - acc: 0.5821 - val_loss: 1.3689 - val_acc: 0.5146\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1747 - acc: 0.5873 - val_loss: 1.3494 - val_acc: 0.5215\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1600 - acc: 0.5913 - val_loss: 1.3770 - val_acc: 0.5169\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1472 - acc: 0.5976 - val_loss: 1.3620 - val_acc: 0.5224\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1322 - acc: 0.6022 - val_loss: 1.4063 - val_acc: 0.5062\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1192 - acc: 0.6053 - val_loss: 1.3555 - val_acc: 0.5218\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1080 - acc: 0.6094 - val_loss: 1.3471 - val_acc: 0.5279\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0927 - acc: 0.6161 - val_loss: 1.4364 - val_acc: 0.5092\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0806 - acc: 0.6215 - val_loss: 1.3700 - val_acc: 0.5153\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0687 - acc: 0.6240 - val_loss: 1.3409 - val_acc: 0.5318\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0543 - acc: 0.6291 - val_loss: 1.3390 - val_acc: 0.5266\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.0388 - acc: 0.6347 - val_loss: 1.3502 - val_acc: 0.5331\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0280 - acc: 0.6383 - val_loss: 1.3751 - val_acc: 0.5231\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0187 - acc: 0.6431 - val_loss: 1.4061 - val_acc: 0.5176\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.0058 - acc: 0.6455 - val_loss: 1.4241 - val_acc: 0.5154\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9897 - acc: 0.6534 - val_loss: 1.3828 - val_acc: 0.5236\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9784 - acc: 0.6576 - val_loss: 1.3952 - val_acc: 0.5203\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.9667 - acc: 0.6590 - val_loss: 1.3819 - val_acc: 0.5310\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9549 - acc: 0.6658 - val_loss: 1.4435 - val_acc: 0.5142\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9394 - acc: 0.6696 - val_loss: 1.5271 - val_acc: 0.4928\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.9284 - acc: 0.6739 - val_loss: 1.3903 - val_acc: 0.5220\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9191 - acc: 0.6794 - val_loss: 1.5045 - val_acc: 0.4984\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.9063 - acc: 0.6817 - val_loss: 1.3651 - val_acc: 0.5387\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.8918 - acc: 0.6878 - val_loss: 1.3848 - val_acc: 0.5316\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.8779 - acc: 0.6915 - val_loss: 1.4719 - val_acc: 0.5105\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.1982 - acc: 0.2031 - val_loss: 2.1014 - val_acc: 0.2583\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.0399 - acc: 0.2768 - val_loss: 1.9856 - val_acc: 0.3099\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.9452 - acc: 0.3218 - val_loss: 1.9120 - val_acc: 0.3350\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8855 - acc: 0.3441 - val_loss: 1.8665 - val_acc: 0.3488\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8452 - acc: 0.3590 - val_loss: 1.8294 - val_acc: 0.3660\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.8139 - acc: 0.3693 - val_loss: 1.8035 - val_acc: 0.3744\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7881 - acc: 0.3800 - val_loss: 1.7808 - val_acc: 0.3829\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7657 - acc: 0.3859 - val_loss: 1.7594 - val_acc: 0.3915\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7450 - acc: 0.3937 - val_loss: 1.7436 - val_acc: 0.3967\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7264 - acc: 0.3998 - val_loss: 1.7232 - val_acc: 0.4020\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7098 - acc: 0.4062 - val_loss: 1.7118 - val_acc: 0.4010\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.6946 - acc: 0.4104 - val_loss: 1.6931 - val_acc: 0.4148\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.6792 - acc: 0.4165 - val_loss: 1.6892 - val_acc: 0.4045\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6660 - acc: 0.4201 - val_loss: 1.6681 - val_acc: 0.4160\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6534 - acc: 0.4245 - val_loss: 1.6560 - val_acc: 0.4200\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6410 - acc: 0.4292 - val_loss: 1.6476 - val_acc: 0.4229\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6295 - acc: 0.4327 - val_loss: 1.6419 - val_acc: 0.4262\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6189 - acc: 0.4363 - val_loss: 1.6277 - val_acc: 0.4341\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6092 - acc: 0.4401 - val_loss: 1.6189 - val_acc: 0.4360\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5987 - acc: 0.4434 - val_loss: 1.6134 - val_acc: 0.4335\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.5900 - acc: 0.4451 - val_loss: 1.5970 - val_acc: 0.4419\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5794 - acc: 0.4498 - val_loss: 1.5908 - val_acc: 0.4462\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.5715 - acc: 0.4518 - val_loss: 1.5841 - val_acc: 0.4446\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5632 - acc: 0.4544 - val_loss: 1.5762 - val_acc: 0.4482\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5546 - acc: 0.4574 - val_loss: 1.5724 - val_acc: 0.4510\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5469 - acc: 0.4602 - val_loss: 1.5681 - val_acc: 0.4466\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5393 - acc: 0.4633 - val_loss: 1.5664 - val_acc: 0.4487\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5319 - acc: 0.4657 - val_loss: 1.5526 - val_acc: 0.4588\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5248 - acc: 0.4664 - val_loss: 1.5579 - val_acc: 0.4549\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5174 - acc: 0.4693 - val_loss: 1.5388 - val_acc: 0.4602\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5110 - acc: 0.4707 - val_loss: 1.5385 - val_acc: 0.4588\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5035 - acc: 0.4758 - val_loss: 1.5286 - val_acc: 0.4634\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4978 - acc: 0.4752 - val_loss: 1.5318 - val_acc: 0.4602\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4920 - acc: 0.4786 - val_loss: 1.5172 - val_acc: 0.4638\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4852 - acc: 0.4818 - val_loss: 1.5219 - val_acc: 0.4663\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4794 - acc: 0.4832 - val_loss: 1.5171 - val_acc: 0.4650\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4725 - acc: 0.4843 - val_loss: 1.5217 - val_acc: 0.4611\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4674 - acc: 0.4851 - val_loss: 1.5214 - val_acc: 0.4670\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4602 - acc: 0.4897 - val_loss: 1.5067 - val_acc: 0.4675\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4552 - acc: 0.4913 - val_loss: 1.5046 - val_acc: 0.4720\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4485 - acc: 0.4932 - val_loss: 1.4961 - val_acc: 0.4707\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4427 - acc: 0.4967 - val_loss: 1.4886 - val_acc: 0.4736\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4375 - acc: 0.4978 - val_loss: 1.4830 - val_acc: 0.4781\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4316 - acc: 0.5009 - val_loss: 1.4799 - val_acc: 0.4798\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4253 - acc: 0.5015 - val_loss: 1.4770 - val_acc: 0.4810\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4209 - acc: 0.5034 - val_loss: 1.4705 - val_acc: 0.4819\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4143 - acc: 0.5052 - val_loss: 1.4656 - val_acc: 0.4866\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4088 - acc: 0.5081 - val_loss: 1.4872 - val_acc: 0.4758\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4025 - acc: 0.5099 - val_loss: 1.4712 - val_acc: 0.4830\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3974 - acc: 0.5122 - val_loss: 1.4578 - val_acc: 0.4873\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 2.2113 - acc: 0.2007 - val_loss: 2.1304 - val_acc: 0.2503\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 56us/step - loss: 2.0858 - acc: 0.2647 - val_loss: 2.0433 - val_acc: 0.2809\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.0153 - acc: 0.2900 - val_loss: 1.9881 - val_acc: 0.2986\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.9662 - acc: 0.3078 - val_loss: 1.9455 - val_acc: 0.3116\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.9280 - acc: 0.3218 - val_loss: 1.9153 - val_acc: 0.3213\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.8983 - acc: 0.3327 - val_loss: 1.8863 - val_acc: 0.3407\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.8733 - acc: 0.3439 - val_loss: 1.8641 - val_acc: 0.3450\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.8518 - acc: 0.3532 - val_loss: 1.8444 - val_acc: 0.3534\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.8327 - acc: 0.3598 - val_loss: 1.8283 - val_acc: 0.3626\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.8158 - acc: 0.3659 - val_loss: 1.8096 - val_acc: 0.3684\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.8003 - acc: 0.3715 - val_loss: 1.7965 - val_acc: 0.3720\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7858 - acc: 0.3780 - val_loss: 1.7839 - val_acc: 0.3755\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7729 - acc: 0.3822 - val_loss: 1.7707 - val_acc: 0.3800\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7601 - acc: 0.3868 - val_loss: 1.7590 - val_acc: 0.3854\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.7486 - acc: 0.3918 - val_loss: 1.7479 - val_acc: 0.3911\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7379 - acc: 0.3951 - val_loss: 1.7380 - val_acc: 0.3922\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7277 - acc: 0.3986 - val_loss: 1.7260 - val_acc: 0.3950\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7179 - acc: 0.3998 - val_loss: 1.7188 - val_acc: 0.3992\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.7091 - acc: 0.4047 - val_loss: 1.7120 - val_acc: 0.4020\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.7004 - acc: 0.4074 - val_loss: 1.7010 - val_acc: 0.4029\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6924 - acc: 0.4099 - val_loss: 1.6929 - val_acc: 0.4073\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6843 - acc: 0.4127 - val_loss: 1.6863 - val_acc: 0.4089\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6769 - acc: 0.4134 - val_loss: 1.6787 - val_acc: 0.4092\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6695 - acc: 0.4174 - val_loss: 1.6738 - val_acc: 0.4144\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6624 - acc: 0.4207 - val_loss: 1.6705 - val_acc: 0.4158\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6557 - acc: 0.4211 - val_loss: 1.6592 - val_acc: 0.4180\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6488 - acc: 0.4244 - val_loss: 1.6522 - val_acc: 0.4184\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6430 - acc: 0.4268 - val_loss: 1.6547 - val_acc: 0.4144\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6366 - acc: 0.4287 - val_loss: 1.6429 - val_acc: 0.4232\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6306 - acc: 0.4316 - val_loss: 1.6384 - val_acc: 0.4240\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6248 - acc: 0.4340 - val_loss: 1.6311 - val_acc: 0.4254\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6190 - acc: 0.4355 - val_loss: 1.6264 - val_acc: 0.4249\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6132 - acc: 0.4373 - val_loss: 1.6248 - val_acc: 0.4269\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6080 - acc: 0.4388 - val_loss: 1.6177 - val_acc: 0.4261\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6024 - acc: 0.4397 - val_loss: 1.6168 - val_acc: 0.4285\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5974 - acc: 0.4439 - val_loss: 1.6065 - val_acc: 0.4344\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5920 - acc: 0.4444 - val_loss: 1.6023 - val_acc: 0.4315\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5865 - acc: 0.4467 - val_loss: 1.5969 - val_acc: 0.4384\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5817 - acc: 0.4489 - val_loss: 1.5912 - val_acc: 0.4375\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5773 - acc: 0.4494 - val_loss: 1.5962 - val_acc: 0.4327\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5730 - acc: 0.4517 - val_loss: 1.5839 - val_acc: 0.4419\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5678 - acc: 0.4536 - val_loss: 1.5815 - val_acc: 0.4452\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5629 - acc: 0.4562 - val_loss: 1.5763 - val_acc: 0.4423\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5591 - acc: 0.4571 - val_loss: 1.5723 - val_acc: 0.4472\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5546 - acc: 0.4579 - val_loss: 1.5708 - val_acc: 0.4440\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5502 - acc: 0.4597 - val_loss: 1.5689 - val_acc: 0.4434\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5454 - acc: 0.4625 - val_loss: 1.5642 - val_acc: 0.4478\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5414 - acc: 0.4630 - val_loss: 1.5716 - val_acc: 0.4435\n",
      "Epoch 49/50\n",
      "37120/50000 [=====================>........] - ETA: 0s - loss: 1.5401 - acc: 0.4605"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for M in MOMENTUM:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    #print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=M)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = str(M)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
